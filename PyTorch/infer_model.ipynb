{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75c72c67-24d8-42a7-9272-e25bf68bf7dc",
   "metadata": {},
   "source": [
    "# Predict new flight positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257cf1d2-a1f3-477b-b640-4fddf3780274",
   "metadata": {},
   "source": [
    "## 1. Load the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7124869c-33c5-4afb-be5e-8e5ec27c4bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FlightModel(\n",
       "  (embedding_layer): PositionEmbedding(\n",
       "    (position_emb): Embedding(1024, 5)\n",
       "  )\n",
       "  (transformer): TransformerBlock(\n",
       "    (attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=5, out_features=5, bias=True)\n",
       "    )\n",
       "    (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "    (layer_norm_1): LayerNorm((5,), eps=1e-06, elementwise_affine=True)\n",
       "    (ffn_1): Linear(in_features=5, out_features=15, bias=True)\n",
       "    (ffn_2): Linear(in_features=15, out_features=5, bias=True)\n",
       "    (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    (layer_norm_2): LayerNorm((5,), eps=1e-06, elementwise_affine=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (output_layer): Linear(in_features=5, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Check device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Context size of our custom model\n",
    "context_size = 1024\n",
    "\n",
    "class PositionEmbedding(torch.nn.Module):\n",
    "    \"\"\"Token and positioning embedding layer for a sequence.\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Init variables and layers.\"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.position_emb = torch.nn.Embedding(num_embeddings=context_size, embedding_dim=5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward Pass.\"\"\"\n",
    "        len_input = x.size()[1]\n",
    "        positions = torch.arange(start=0, end=len_input, step=1).to(device)\n",
    "        position_embedding = self.position_emb(positions)\n",
    "        return x + position_embedding\n",
    "\n",
    "def create_attention_mask(key_length, query_length, dtype):\n",
    "    \"\"\"\n",
    "    Create a Casual Mask for\n",
    "    the multi head attention layer.\n",
    "    \"\"\"\n",
    "    i = torch.arange(query_length)[:, None]\n",
    "    j = torch.arange(key_length)\n",
    "    mask = i >= j - key_length + query_length\n",
    "    mask = torch.logical_not(mask)\n",
    "    mask = mask.to(dtype)\n",
    "    return mask\n",
    "\n",
    "class TransformerBlock(torch.nn.Module):\n",
    "    \"\"\"Transformer Block Layer.\"\"\"\n",
    "    def __init__(self, num_heads, embed_dim, ff_dim, mask_function, dropout_rate=0.1):\n",
    "        \"\"\"Init variables and layers.\"\"\"\n",
    "        super().__init__()\n",
    "        self.attn = torch.nn.MultiheadAttention(\n",
    "          embed_dim=embed_dim,\n",
    "          num_heads=num_heads,\n",
    "          batch_first=True,\n",
    "        )\n",
    "        self.dropout_1 = torch.nn.Dropout(p=dropout_rate)\n",
    "        self.layer_norm_1 = torch.nn.LayerNorm(\n",
    "          normalized_shape=embed_dim, eps=1e-6\n",
    "        )\n",
    "        self.ffn_1 = torch.nn.Linear(\n",
    "          in_features=embed_dim, out_features=ff_dim\n",
    "        )\n",
    "        self.ffn_2 = torch.nn.Linear(\n",
    "          in_features=ff_dim, out_features=embed_dim\n",
    "        )\n",
    "        self.dropout_2 = torch.nn.Dropout(p=dropout_rate)\n",
    "        self.layer_norm_2 = torch.nn.LayerNorm(\n",
    "          normalized_shape=embed_dim, eps=1e-6\n",
    "        )\n",
    "        self.mask_function = mask_function\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward Pass.\"\"\"\n",
    "        seq_len = inputs.size()[1]\n",
    "        mask = self.mask_function(seq_len, seq_len, torch.bool).to(device)\n",
    "        attention_output, _ = self.attn(\n",
    "        query=inputs, key=inputs, value=inputs, attn_mask=mask\n",
    "        )\n",
    "        attention_output = self.dropout_1(attention_output)\n",
    "        out1 = self.layer_norm_1(inputs + attention_output)\n",
    "        ffn_1 = self.relu(self.ffn_1(out1))\n",
    "        ffn_2 = self.ffn_2(ffn_1)\n",
    "        ffn_output = self.dropout_2(ffn_2)\n",
    "        output = self.layer_norm_2(out1 + ffn_output)\n",
    "        return output\n",
    "\n",
    "class FlightModel(torch.nn.Module):\n",
    "  def __init__(self, feed_forward_dim, num_heads):\n",
    "    \"\"\"Init Function.\"\"\"\n",
    "    super().__init__()\n",
    "    self.embedding_layer = PositionEmbedding()\n",
    "    self.transformer = TransformerBlock(\n",
    "      num_heads=num_heads,\n",
    "      embed_dim=5,\n",
    "      ff_dim=feed_forward_dim,\n",
    "      mask_function=create_attention_mask,\n",
    "    )\n",
    "    self.output_layer = torch.nn.Linear(5, 5)\n",
    "\n",
    "  def forward(self, input_tensor):\n",
    "    \"\"\"Forward Pass.\"\"\"\n",
    "    embedding = self.embedding_layer(input_tensor)\n",
    "    transformer_output = self.transformer(embedding)\n",
    "    output = self.output_layer(transformer_output)\n",
    "    return output\n",
    "\n",
    "model = FlightModel(15, 1).to(device)\n",
    "model.load_state_dict(torch.load(\"./flight_prediction_model.pt\", weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09efbe1e-d5f5-437d-9fe0-00c5c1074ab2",
   "metadata": {},
   "source": [
    "## 2. Generate new plane positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "facf31c7-bee8-49e1-9ccd-b90309875e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-3.3626e+01, -7.0909e+01,  1.4550e+04,  3.2790e+02,  2.2000e+01],\n",
      "         [-3.3608e+01, -7.0900e+01,  1.4225e+04,  3.2440e+02,  2.1900e+01],\n",
      "         [-3.7404e-01, -1.8128e-01,  1.6897e+00,  5.2111e-01, -1.5914e-01],\n",
      "         [-6.2614e-01, -4.0731e-01,  1.4264e+00,  3.0886e-01, -3.9758e-01],\n",
      "         [-1.0975e+00, -4.8190e-01,  6.5662e-01,  4.8041e-01,  1.4114e+00],\n",
      "         [-7.5327e-01, -3.8382e-01,  2.5688e-01,  1.9122e-01,  1.5512e+00],\n",
      "         [-7.4129e-01, -3.9461e-01,  1.5629e+00,  4.4036e-01,  1.1812e+00],\n",
      "         [ 7.3108e-02, -3.6159e-02,  1.1081e+00,  1.5331e-01,  4.4667e-01],\n",
      "         [ 1.2465e-01, -1.1690e-01,  6.7534e-01, -1.1533e-01, -8.1817e-01],\n",
      "         [-6.2637e-01, -4.0750e-01,  1.4261e+00,  3.0869e-01, -3.9751e-01],\n",
      "         [-5.7736e-04, -2.4731e-02,  1.2980e+00,  3.0758e-01,  2.8266e-01],\n",
      "         [-6.2620e-01, -4.0743e-01,  1.4262e+00,  3.0866e-01, -3.9760e-01]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "plane_pos_1 = [-33.625946, -70.909181, 14550, 327.9, 22]\n",
    "plane_pos_2 = [-33.607635, -70.900381, 14225, 324.4, 21.9]\n",
    "plane_pos = [plane_pos_1, plane_pos_2]\n",
    "pos_input = torch.tensor(plane_pos)\n",
    "pos_input = pos_input.view(1, -1, 5)\n",
    "pos_input = pos_input.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(10):  \n",
    "        output = model(pos_input)\n",
    "        output = torch.squeeze(output)\n",
    "        output = output[-1]\n",
    "        output = output.view(1, 1, 5)\n",
    "        pos_input = torch.cat((pos_input, output), 1)\n",
    "\n",
    "print(pos_input)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
