{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "847e8d5a",
   "metadata": {},
   "source": [
    "# Train a Transformer model to predict the flight path of a plane"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c77d11",
   "metadata": {},
   "source": [
    "This notebook assumes that you have ran the previous notebook to obtain training data, `retrieve_flight_training_data.ipynb`, and that PyTorch (and other standard data science related libraries) are already installed. Kaggle notebook here: https://www.kaggle.com/code/matthiaswang62/train-flightpathpredictor/script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9400cf6",
   "metadata": {},
   "source": [
    "## 1. Imports and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9f4c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Check device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Context size of our custom model\n",
    "context_size = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca72b99",
   "metadata": {},
   "source": [
    "## 2. Create a custom Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8768955",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlightDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # We are going to feed in positional data in batches of 1024 positions (we add 1 because when we get data we minus off last/first data point)\n",
    "        self.max_len = 1024 + 1\n",
    "\n",
    "        # We will not load all 80k csv files at once, we will load them on demand during training\n",
    "        # However, we will need to keep a record of which files correspond to which data points, so we can get them by index\n",
    "        self.train_files = []\n",
    "        self.train_sections = []\n",
    "        \n",
    "        for file in os.listdir(\"./data/csv\"):\n",
    "            if file.endswith(\".csv\") == False:\n",
    "                continue\n",
    "            # Read csv file and keep a record of it in the training lists\n",
    "            csv_path = os.path.join(\"./data/csv\", file)\n",
    "            with open(csv_path) as fp:\n",
    "                count = 0\n",
    "                for _ in fp:\n",
    "                    count += 1\n",
    "                # Exclude header row\n",
    "                count -= 1\n",
    "                num_sections = math.floor(count / self.max_len) + 1\n",
    "                for i in range(num_sections):\n",
    "                    self.train_files.append(csv_path)\n",
    "                    self.train_sections.append(i)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.train_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Read corresponding csv file\n",
    "        csv_reader = pd.read_csv(self.train_files[idx])\n",
    "\n",
    "        # Convert csv data into a tensor\n",
    "        pos_embedding = torch.tensor(csv_reader.values, dtype=torch.float)\n",
    "        pos_embedding = pos_embedding.view(1, -1, 6)\n",
    "\n",
    "         # Split tensor based on max_len\n",
    "        num_sections = math.floor(pos_embedding.size()[1] / self.max_len) + 1\n",
    "        embedding_list = torch.tensor_split(pos_embedding, num_sections, dim=1)\n",
    "        \n",
    "        # Get the tensor to return\n",
    "        pos_sentence = embedding_list[self.train_sections[idx]]\n",
    "        \n",
    "        # Pad if necessary\n",
    "        tensor_length = pos_sentence.size()[1]\n",
    "        if tensor_length < self.max_len:\n",
    "            num_to_pad = self.max_len - tensor_length\n",
    "            zero_tensor = torch.zeros([1, num_to_pad, 6])\n",
    "            pos_sentence = torch.cat((pos_sentence, zero_tensor), 1)\n",
    "\n",
    "        pos_sentence = torch.squeeze(pos_sentence)\n",
    "\n",
    "        # For faster training, divide the values in the embedding\n",
    "        div_tensor = torch.tensor([90,  180, 10000, 1000, 360, 10000])\n",
    "        pos_sentence = torch.div(pos_sentence, div_tensor)\n",
    "        \n",
    "        return pos_sentence[:-1], pos_sentence[1:]\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50183051-0f22-4db5-8acb-92070bf7e402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test our custom dataset\n",
    "train_dataset = FlightDataset()\n",
    "sample, target = train_dataset.__getitem__(69)\n",
    "print(sample.size())\n",
    "print(target.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252c1b5d-1eae-4706-b4a7-d2e3bc1a7525",
   "metadata": {},
   "source": [
    "## 3. Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf959203-2743-4f5a-a89d-9e194fdd6f5c",
   "metadata": {},
   "source": [
    "### Position embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768549b0-3da6-4a96-aeeb-d2fc1a4a20f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionEmbedding(torch.nn.Module):\n",
    "    \"\"\"Token and positioning embedding layer for a sequence.\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Init variables and layers.\"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.position_emb = torch.nn.Embedding(num_embeddings=context_size, embedding_dim=6)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward Pass.\"\"\"\n",
    "        len_input = x.size()[1]\n",
    "        positions = torch.arange(start=0, end=len_input, step=1).to(device)\n",
    "        position_embedding = self.position_emb(positions)\n",
    "        return x + position_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d64c265-5d3e-4465-a768-d5024a3707bc",
   "metadata": {},
   "source": [
    "### Attention mask function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348599e8-50ef-46f8-ae36-c7da24391a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_attention_mask(key_length, query_length, dtype):\n",
    "    \"\"\"\n",
    "    Create a Casual Mask for\n",
    "    the multi head attention layer.\n",
    "    \"\"\"\n",
    "    i = torch.arange(query_length)[:, None]\n",
    "    j = torch.arange(key_length)\n",
    "    mask = i >= j - key_length + query_length\n",
    "    mask = torch.logical_not(mask)\n",
    "    mask = mask.to(dtype)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82c3b51-72fc-4a61-859a-4574d55ceb7e",
   "metadata": {},
   "source": [
    "### Transformer block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6bbb56-851a-42c4-b46a-28d32c746b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(torch.nn.Module):\n",
    "    \"\"\"Transformer Block Layer.\"\"\"\n",
    "    def __init__(self, num_heads, embed_dim, ff_dim, mask_function, dropout_rate=0.1):\n",
    "        \"\"\"Init variables and layers.\"\"\"\n",
    "        super().__init__()\n",
    "        self.attn = torch.nn.MultiheadAttention(\n",
    "          embed_dim=embed_dim,\n",
    "          num_heads=num_heads,\n",
    "          batch_first=True,\n",
    "        )\n",
    "        self.dropout_1 = torch.nn.Dropout(p=dropout_rate)\n",
    "        self.layer_norm_1 = torch.nn.LayerNorm(\n",
    "          normalized_shape=embed_dim, eps=1e-6\n",
    "        )\n",
    "        self.ffn_1 = torch.nn.Linear(\n",
    "          in_features=embed_dim, out_features=ff_dim\n",
    "        )\n",
    "        self.ffn_2 = torch.nn.Linear(\n",
    "          in_features=ff_dim, out_features=embed_dim\n",
    "        )\n",
    "        self.dropout_2 = torch.nn.Dropout(p=dropout_rate)\n",
    "        self.layer_norm_2 = torch.nn.LayerNorm(\n",
    "          normalized_shape=embed_dim, eps=1e-6\n",
    "        )\n",
    "        self.mask_function = mask_function\n",
    "        \n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward Pass.\"\"\"\n",
    "        seq_len = inputs.size()[1]\n",
    "        mask = self.mask_function(seq_len, seq_len, torch.bool).to(device)\n",
    "        attention_output, _ = self.attn(\n",
    "        query=inputs, key=inputs, value=inputs, attn_mask=mask\n",
    "        )\n",
    "        attention_output = self.dropout_1(attention_output)\n",
    "        out1 = self.layer_norm_1(inputs + attention_output)\n",
    "        ffn_1 = self.ffn_1(out1)\n",
    "        ffn_2 = self.ffn_2(ffn_1)\n",
    "        ffn_output = self.dropout_2(ffn_2)\n",
    "        output = self.layer_norm_2(out1 + ffn_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c77c53-c73d-414d-914f-4b9a45cae4fd",
   "metadata": {},
   "source": [
    "### Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781d62d0-6328-4348-83cf-07d96c8a8d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlightModel(torch.nn.Module):\n",
    "  def __init__(self, feed_forward_dim, num_heads):\n",
    "    \"\"\"Init Function.\"\"\"\n",
    "    super().__init__()\n",
    "    self.embedding_layer = PositionEmbedding()\n",
    "    self.transformer_layers = []\n",
    "    for i in range(6):\n",
    "        transformer = TransformerBlock(\n",
    "          num_heads=num_heads,\n",
    "          embed_dim=6,\n",
    "          ff_dim=feed_forward_dim,\n",
    "          mask_function=create_attention_mask,\n",
    "        )\n",
    "        self.transformer_layers.append(transformer)\n",
    "    self.transformer_layers = nn.ModuleList(self.transformer_layers)\n",
    "    self.output_layer = torch.nn.Linear(6, 6)\n",
    "\n",
    "  def forward(self, input_tensor):\n",
    "    \"\"\"Forward Pass.\"\"\"\n",
    "    # Position embedding\n",
    "    embedding = self.embedding_layer(input_tensor)\n",
    "    # Transformer layers\n",
    "    transformer_output = self.transformer_layers[0](embedding)\n",
    "    for i in range(1, len(self.transformer_layers)):\n",
    "        transformer_output = self.transformer_layers[i](transformer_output)\n",
    "    # FC network\n",
    "    output = self.output_layer(transformer_output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791dcff2-d7b7-43ca-8fbe-5f5bf5d007f8",
   "metadata": {},
   "source": [
    "### Custom loss function to penalise predictions with the wrong sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4cf645-d4bc-40ba-a072-269ec44eca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSENegReLU(output, target):\n",
    "    loss = torch.mean((output - target)**2)\n",
    "    # Penalise predictions that have the wrong sign from the target\n",
    "    relu = torch.nn.ReLU()\n",
    "    penalty = torch.mean(2 * relu(torch.neg(torch.mul(output, target))))\n",
    "    return loss + penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972110f5-1ffb-45e0-a20f-c1d1c3d610fb",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac420ef2-b00d-4cc6-956c-33c5fef6407b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = FlightModel(24, 1).to(device)\n",
    "optimizer = torch.optim.Adam(params=filter(lambda param: param.requires_grad, model.parameters()), lr=0.0001)\n",
    "print(\"Loading Data...\")\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "train_losses = []\n",
    "\n",
    "def train_network(model, num_epochs):\n",
    "    \"\"\"Train the Network.\"\"\"\n",
    "    print(\"Training Started.\")\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        running_train_loss = 0.0\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            x = batch[0].to(device)\n",
    "            y = batch[1].to(device)\n",
    "            outputs = model(x)\n",
    "            loss = MSENegReLU(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch}/{num_epochs}, Train Loss: {running_train_loss / len(train_loader)}\")\n",
    "        train_losses.append(running_train_loss / len(train_loader))\n",
    "        # Save model\n",
    "        torch.save(model.state_dict(), f\"./flight_prediction_model_{epoch}.pt\")\n",
    "\n",
    "train_network(model, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a90582-d830-4a47-a451-bdc9fa88ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146a163d-a6f6-4a57-a9e3-1a80dfd0d9eb",
   "metadata": {},
   "source": [
    "## 5. Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d965549-628b-4a71-9968-c63362528f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./flight_prediction_model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
